{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14823bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WIN10\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import one_hot, resize_to_ori_calMAE, resize_to_ori\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182b7aca",
   "metadata": {},
   "source": [
    "# Define save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4af1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'election_GAN(pytorch)/'\n",
    "gen_results = 'generated_results/'\n",
    "\n",
    "model = 'model_'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "if not os.path.isdir(folder + gen_results):\n",
    "    os.mkdir(folder + gen_results)\n",
    "\n",
    "# save ckpt\n",
    "saver_path = os.path.join(folder, model)\n",
    "\n",
    "# save generated data\n",
    "generated_path = os.path.join(folder + gen_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbfa907",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61daac8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 24, 30)\n",
      "(1000, 24, 30)\n",
      "(2000, 24, 30)\n"
     ]
    }
   ],
   "source": [
    "img_width = 30\n",
    "img_height = 24\n",
    "\n",
    "data_alt3 = pd.read_csv('./data/netflix_data_3alt_resize.csv')\n",
    "data_alt3 = data_alt3.iloc[:1000,1:].values\n",
    "\n",
    "data_alt3 = data_alt3.reshape([-1, img_height, img_width])\n",
    "print(data_alt3.shape)\n",
    "\n",
    "##################################\n",
    "data_alt4 = pd.read_csv('./data/netflix_data_4alt_resize.csv')\n",
    "data_alt4 = data_alt4.iloc[:1000,1:].values\n",
    "\n",
    "data_alt4 = data_alt4.reshape([-1, img_height, img_width])\n",
    "print(data_alt4.shape)\n",
    "\n",
    "data_alt_3_4 = np.concatenate( (data_alt3, data_alt4), axis = 0)\n",
    "print(data_alt_3_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20698c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.cla()\n",
    "# ax.imshow(np.reshape(data_alt3[2], (data_alt3.shape[1], data_alt3.shape[2])), cmap='gray')\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.cla()\n",
    "# ax.imshow(np.reshape(data_alt4[99], (data_alt3.shape[1], data_alt3.shape[2])), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b209522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "label_alt3 = np.zeros([data_alt3.shape[0]])\n",
    "label_alt4 = np.zeros([data_alt4.shape[0]]) + 1\n",
    "label_alt_3_4 = np.concatenate( (label_alt3,label_alt4), axis = 0)\n",
    "\n",
    "label_alt_onehot = one_hot(label_alt_3_4, 1 + 1)   \n",
    "print(label_alt_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839d77cd",
   "metadata": {},
   "source": [
    "# resize the data into original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68874518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_alt3_ori:  (1000, 6)\n",
      "data_alt4_ori:  (1000, 24)\n"
     ]
    }
   ],
   "source": [
    "data_alt3_ori = resize_to_ori_calMAE(data_alt3, np.math.factorial(6), img_width, img_height, np.math.factorial(3))\n",
    "print('data_alt3_ori: ', data_alt3_ori.shape)\n",
    "\n",
    "data_alt4_ori = resize_to_ori_calMAE(data_alt4, np.math.factorial(6), img_width, img_height, np.math.factorial(4))\n",
    "print('data_alt4_ori: ', data_alt4_ori.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661edfe8",
   "metadata": {},
   "source": [
    "# cal MAE_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a313b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n",
      "(1000000,)\n",
      "0.14297275102413617\n",
      "0.041658739360209994\n"
     ]
    }
   ],
   "source": [
    "MAE_train_train_alt3 = []\n",
    "MAE_train_train_alt4 = []\n",
    "for i in range(len(data_alt3_ori)):\n",
    "    for j in range(len(data_alt3_ori)):\n",
    "        MAE_train_train_alt3.append(np.mean(np.abs(data_alt3_ori[i] - data_alt3_ori[j])))     \n",
    "        MAE_train_train_alt4.append(np.mean(np.abs(data_alt4_ori[i] - data_alt4_ori[j])))    \n",
    "        \n",
    "MAE_train_train_alt3 = np.array(MAE_train_train_alt3)\n",
    "MAE_train_train_alt4 = np.array(MAE_train_train_alt4)\n",
    "print(MAE_train_train_alt3.shape)\n",
    "print(MAE_train_train_alt4.shape)\n",
    "\n",
    "MAE_train_train_alt3_mean = np.mean(MAE_train_train_alt3)\n",
    "MAE_train_train_alt4_mean = np.mean(MAE_train_train_alt4)\n",
    "print(MAE_train_train_alt3_mean)\n",
    "print(MAE_train_train_alt4_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06608d70",
   "metadata": {},
   "source": [
    "# Define Generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57caff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(dis, x_real, x_fake, x_label, device=\"cpu\"):\n",
    "    batch_size, height, width = x_real.shape\n",
    "    alpha = torch.rand((batch_size, 1, 1)).repeat(1, height, width).to(device)\n",
    "    interpolated_images = x_real * alpha + x_fake * (1 - alpha)\n",
    "\n",
    "    # Calculate dis scores\n",
    "    mixed_scores = dis(interpolated_images, x_label)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d71da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim = 128, num_classes = 2):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dim = 128\n",
    "        self.hidden = torch.nn.Linear(z_dim + num_classes, self.dim*1*1*3)   \n",
    "        self.tconv1 = self.conv_block(self.dim*3, self.dim*3, k_size=[1,5], stride=[1,5], pad=0, out_pad=0, use_bn=False)\n",
    "        self.tconv2 = self.conv_block(self.dim*3, self.dim*2, k_size=[4,1], stride=[4,1], pad=0, out_pad=0, use_bn=False)\n",
    "        self.tconv3 = self.conv_block(self.dim*2, self.dim*1, k_size=[3,3], stride=[3,3], pad=0, out_pad=0, use_bn=False)\n",
    "        self.tconv4 = self.conv_block(self.dim*1, 1, k_size=[2,2], stride=[2,2], pad=0, out_pad=0, use_bn=False)        \n",
    "        \n",
    "    def conv_block(self, c_in, c_out, k_size, stride, pad, out_pad, use_bn=False):\n",
    "        module = []\n",
    "        module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, padding=pad, output_padding=out_pad, bias=not use_bn))\n",
    "        if use_bn: module.append(nn.BatchNorm2d(c_out))\n",
    "        return nn.Sequential(*module)        \n",
    "\n",
    "    def forward(self, x, label):\n",
    "        x = x.reshape([x.shape[0], -1, 1, 1])\n",
    "        label = label.reshape([x.shape[0], -1, 1, 1])\n",
    "        x = torch.cat((x, label), dim=1).reshape([x.shape[0], -1])\n",
    "        x = F.relu(self.hidden(x)).reshape([x.shape[0], 3*self.dim, 1, 1])\n",
    "        x = F.relu(self.tconv1(x))\n",
    "        x = F.relu(self.tconv2(x))\n",
    "        x = self.tconv3(x)\n",
    "        x = self.tconv4(x)\n",
    "        \n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e98a6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''padding: same'''\n",
    "\n",
    "class Conv2dSame(torch.nn.Conv2d):\n",
    "\n",
    "    def calc_same_pad(self, i: int, k: int, s: int, d: int) -> int:\n",
    "        return max((math.ceil(i / s) - 1) * s + (k - 1) * d + 1 - i, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ih, iw = x.size()[-2:]\n",
    "\n",
    "        pad_h = self.calc_same_pad(i=ih, k=self.kernel_size[0], s=self.stride[0], d=self.dilation[0])\n",
    "        pad_w = self.calc_same_pad(i=iw, k=self.kernel_size[1], s=self.stride[1], d=self.dilation[1])\n",
    "\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            x = F.pad(\n",
    "                x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2]\n",
    "            )\n",
    "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes = 2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dim = 128\n",
    "        self.height = 24\n",
    "        self.width = 30\n",
    "        self.conv1 = self.conv_block(1 + num_classes, self.dim, k_size=[4,5], stride=[2,2], pad=0)\n",
    "        self.conv2 = self.conv_block(self.dim, self.dim * 2, k_size=[4,5], stride=[2,2], pad=0)\n",
    "        self.conv3 = self.conv_block(self.dim * 2, self.dim * 2, k_size=[4,5], stride=[2,2], pad=0)\n",
    "        self.hidden = torch.nn.Linear(3072, 1)  \n",
    "\n",
    "    def conv_block(self, c_in, c_out, k_size, stride, pad=0, use_bn=False):\n",
    "        module = []\n",
    "        module.append(Conv2dSame(in_channels=c_in, \n",
    "                                 out_channels=c_out, kernel_size=k_size, stride=stride, groups=1, bias=not use_bn))\n",
    "        if use_bn: module.append(nn.BatchNorm2d(c_out))\n",
    "        return nn.Sequential(*module)        \n",
    "        \n",
    "    def forward(self, x, label):\n",
    "        alpha = 0.2\n",
    "        x = x.reshape([batch_size, 1, self.height, self.width])\n",
    "        label = label.reshape([batch_size, 2, self.height, self.width])\n",
    "        x = torch.cat((x, label), dim=1)\n",
    "        x = F.leaky_relu(self.conv1(x), alpha)\n",
    "        x = F.leaky_relu(self.conv2(x), alpha)\n",
    "        x = self.conv3(x)\n",
    "        x = x.reshape([x.shape[0], -1])\n",
    "        x = self.hidden(x)\n",
    "                        \n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b013f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class election_GAN(object):\n",
    "    def __init__(self,\n",
    "                num_samples = None,\n",
    "                dim_height = None,\n",
    "                dim_width = None,\n",
    "                dim_z = None,\n",
    "                num_class = None,\n",
    "                batch_size = None,\n",
    "                lambda_gp = None):\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#         self.device = \"cpu\" \n",
    "        self.num_samples = num_samples\n",
    "        self.dim_height = dim_height\n",
    "        self.dim_width = dim_width\n",
    "        self.dim_z = dim_z\n",
    "        self.num_class = num_class\n",
    "        self.batch_size = batch_size\n",
    "        self.lambda_gp = lambda_gp\n",
    "       \n",
    "    '''loss curve'''\n",
    "    def show_train_hist(self):\n",
    "        x = range(len(self.train_hist['D_losses']))\n",
    "\n",
    "        y1 = self.train_hist['D_losses']\n",
    "        y2 = self.train_hist['G_losses']\n",
    "\n",
    "        plt.plot(x, y1, label='D_loss')\n",
    "        plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.legend(loc=4)  \n",
    "        plt.grid(True)\n",
    "        plt.tight_layout() \n",
    "        plt.title(\"Training Losses\")\n",
    "\n",
    "        plt.show()  \n",
    "        \n",
    "    def resize_to_ori_calMAE(self, x, img_size, ori_size):\n",
    "        cell_size = int(img_size//ori_size)\n",
    "\n",
    "        ori_dat = []\n",
    "        for j in range(len(x)):\n",
    "            dat = x[j].reshape([self.dim_height*self.dim_width])\n",
    "            tmp = []\n",
    "            for i in range(dat.shape[0] // cell_size):\n",
    "                tmp.append(torch.mean(dat[(i)*cell_size:(i+1)*cell_size]))\n",
    "            ori_dat.append(tmp)\n",
    "        return torch.Tensor(ori_dat).to(self.device)   \n",
    "    \n",
    "    def cal_penalty(self, x_fake, y_all, data_alt3_ori, data_alt4_ori, MAE_train_train_alt3_mean, MAE_train_train_alt4_mean):\n",
    "        \n",
    "        x_fake_alt3, x_fake_alt4 = [], []\n",
    "        for i in range(self.batch_size):\n",
    "            if y_all[i] == 0: x_fake_alt3.append(x_fake[i])\n",
    "            else: x_fake_alt4.append(x_fake[i])\n",
    "\n",
    "        random_seed = np.random.randint(len(data_alt3_ori), size = self.batch_size)\n",
    "        data_alt3_ori_UniformSampling = data_alt3_ori[random_seed]\n",
    "        data_alt4_ori_UniformSampling = data_alt4_ori[random_seed]\n",
    "        \n",
    "        data_alt3_ori_UniformSampling = torch.Tensor(data_alt3_ori_UniformSampling).to(self.device)    \n",
    "        data_alt4_ori_UniformSampling = torch.Tensor(data_alt4_ori_UniformSampling).to(self.device)  \n",
    "        \n",
    "        x_fake_alt3 = self.resize_to_ori_calMAE(x_fake_alt3, np.math.factorial(6), np.math.factorial(3))\n",
    "        x_fake_alt4 = self.resize_to_ori_calMAE(x_fake_alt4, np.math.factorial(6), np.math.factorial(4))\n",
    "\n",
    "        MAE_train_gen_alt3, MAE_train_gen_alt4 = [], []\n",
    "        for i in range(int(self.batch_size)):\n",
    "            for j in range(int(self.batch_size//2)):\n",
    "                MAE_train_gen_alt3.append(torch.mean(torch.abs(data_alt3_ori_UniformSampling[i] - x_fake_alt3[j])))   \n",
    "                MAE_train_gen_alt4.append(torch.mean(torch.abs(data_alt4_ori_UniformSampling[i] - x_fake_alt4[j])))                                 \n",
    "\n",
    "        MAE_train_gen_alt3 = torch.Tensor(MAE_train_gen_alt3)#.to(self.device)  \n",
    "        MAE_train_gen_alt4 = torch.Tensor(MAE_train_gen_alt4)#.to(self.device)   \n",
    "        \n",
    "        delta_MAE_alt3_mean = torch.abs(torch.mean(MAE_train_gen_alt3) - MAE_train_train_alt3_mean)\n",
    "        delta_MAE_alt4_mean = torch.abs(torch.mean(MAE_train_gen_alt4) - MAE_train_train_alt4_mean)        \n",
    "        delta_MAE_mean = delta_MAE_alt3_mean + delta_MAE_alt4_mean\n",
    "        MAE_std = torch.std(MAE_train_gen_alt3) + torch.std(MAE_train_gen_alt4)\n",
    "        MAE_max = torch.max(MAE_train_gen_alt3) + torch.max(MAE_train_gen_alt4)\n",
    "        MAE_min = torch.min(MAE_train_gen_alt3) + torch.min(MAE_train_gen_alt4) \n",
    "        \n",
    "        return delta_MAE_mean, MAE_std, MAE_max, MAE_min\n",
    "    \n",
    "    def train_model(self,\n",
    "                    x_train = None,     \n",
    "                    y_train = None,\n",
    "                    dataloder_num_workers = 1,\n",
    "                    train_epoch = 17000, \n",
    "                    step_valid = 50,\n",
    "                    step_save_data = 1000,\n",
    "                    iteration_generator = None,\n",
    "                    n_critic = 5,\n",
    "                    data_alt3_ori = None,\n",
    "                    data_alt4_ori = None,\n",
    "                    MAE_train_train_alt3_mean = None,\n",
    "                    MAE_train_train_alt4_mean = None,\n",
    "                   ):\n",
    "        '''define gen, dis and optim'''\n",
    "        self.gen = Generator(z_dim = self.dim_z, num_classes = self.num_class).to(self.device)\n",
    "        self.dis = Discriminator(num_classes = self.num_class).to(self.device)\n",
    "\n",
    "        self.g_opt = optim.Adam(self.gen.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "        self.d_opt = optim.Adam(self.dis.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "        \n",
    "        '''load data into dataloder'''\n",
    "        torch_dataset = Data.TensorDataset(torch.Tensor(x_train), torch.Tensor(y_train))\n",
    "\n",
    "        data_loader = Data.DataLoader(dataset = torch_dataset, batch_size = self.batch_size, \n",
    "                                shuffle = True, num_workers = dataloder_num_workers, drop_last = True)\n",
    "        \n",
    "        \n",
    "        ''' Training '''\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "\n",
    "        time_start=time.time()\n",
    "\n",
    "        print('Optimization start!')\n",
    "        for epoch in range(train_epoch):\n",
    "            G_losses = []\n",
    "            D_losses = []\n",
    "\n",
    "            time_start_epoch = time.time()\n",
    "\n",
    "            for i, data in enumerate(data_loader):\n",
    "                x_real, x_label = data        \n",
    "                x_real = x_real.to(self.device)\n",
    "\n",
    "\n",
    "                z_label = x_label.reshape([self.batch_size, self.num_class, 1, 1]).to(self.device)\n",
    "                np_ones = np.ones([self.batch_size, self.num_class, self.dim_height, self.dim_width])\n",
    "                x_label = z_label * torch.Tensor(np_ones).to(self.device)\n",
    "\n",
    "                '''#############        Discriminator       #######################'''\n",
    "                z_fake = torch.randn(self.batch_size, self.dim_z, 1, 1).to(self.device)\n",
    "                x_fake = self.gen(z_fake, z_label)\n",
    "                fake_out = self.dis(x_fake.detach(), x_label)\n",
    "                real_out = self.dis(x_real.detach(), x_label)\n",
    "                gp = gradient_penalty(self.dis, x_real, x_fake, x_label, device = self.device)\n",
    "                self.d_loss = (-(torch.mean(real_out) - torch.mean(fake_out)) + self.lambda_gp * gp)\n",
    "\n",
    "                self.dis.zero_grad()\n",
    "                self.d_loss.backward()\n",
    "                self.d_opt.step()  \n",
    "                D_losses.append(self.d_loss.data.cpu().numpy())\n",
    "\n",
    "                '''#############        Generator          #######################'''\n",
    "                if (i+1) % n_critic == 0:  \n",
    "                    z_fake = torch.randn(self.batch_size, self.dim_z, 1, 1).to(self.device)\n",
    "                    \n",
    "                    ### create label \n",
    "                    y_alt3 = np.zeros([int(self.batch_size//2), 1]) + 0\n",
    "                    y_alt4 = np.zeros([int(self.batch_size//2), 1]) + 1\n",
    "                    y_all = np.concatenate((y_alt3, y_alt4), axis=0).reshape([-1])\n",
    "                    np.random.seed(0)\n",
    "                    np.random.shuffle(y_all)\n",
    "                    z_label = one_hot(y_all, self.num_class).reshape([self.batch_size, self.num_class, 1, 1])\n",
    "                    x_label = z_label * np.ones([self.batch_size, self.num_class, self.dim_height, self.dim_width])\n",
    "                    z_label = torch.Tensor(z_label).to(self.device)    \n",
    "                    x_label = torch.Tensor(x_label).to(self.device)    \n",
    "                    \n",
    "                    x_fake = self.gen(z_fake, z_label)\n",
    "                    fake_out = self.dis(x_fake, x_label)\n",
    "                \n",
    "                    if epoch > 2000: \n",
    "                        delta_MAE_mean, MAE_std, MAE_max, MAE_min = self.cal_penalty(x_fake, y_all, \n",
    "                                    data_alt3_ori, data_alt4_ori, MAE_train_train_alt3_mean, MAE_train_train_alt4_mean)\n",
    "\n",
    "                        self.g_loss = -torch.mean(fake_out) + delta_MAE_mean + 3*MAE_std + MAE_max + -(MAE_min)\n",
    "                        \n",
    "                    else: self.g_loss = -torch.mean(fake_out)                    \n",
    "                                        \n",
    "                    self.g_opt.zero_grad()\n",
    "                    self.g_loss.backward()\n",
    "                    self.g_opt.step()\n",
    "                    G_losses.append(self.g_loss.data.cpu().numpy())\n",
    "\n",
    "\n",
    "            ############        show loss      #######################\n",
    "            if (epoch+1) % 1 == 0:\n",
    "                print('[%d/%d] loss_d: %.3f, loss_g: %.3f'%((epoch + 1), train_epoch, np.mean(D_losses), np.mean(G_losses)))\n",
    "                self.train_hist['D_losses'].append(np.mean(D_losses))\n",
    "                self.train_hist['G_losses'].append(np.mean(G_losses))\n",
    "\n",
    "            ############        visualize generated data      #######################\n",
    "            if (epoch+1) % step_valid == 0:\n",
    "                with torch.no_grad():\n",
    "                   ############        num_alternative = 3      #######################\n",
    "                    z_fake = torch.randn(self.batch_size, self.dim_z, 1, 1).to(self.device)\n",
    "                    z_label = np.zeros([self.batch_size, 1]) + 0\n",
    "                    z_label = one_hot(z_label, self.num_class).reshape([self.batch_size, self.num_class, 1, 1])\n",
    "                    z_label = torch.Tensor(z_label).to(self.device)    \n",
    "\n",
    "                    gen_alt3 = self.gen(z_fake, z_label)\n",
    "                    ############        num_alternative = 4      #######################\n",
    "                    z_fake = torch.randn(self.batch_size, self.dim_z, 1, 1).to(self.device)\n",
    "                    z_label = np.zeros([self.batch_size, 1]) + 1\n",
    "                    z_label = one_hot(z_label, self.num_class).reshape([self.batch_size, self.num_class, 1, 1])\n",
    "                    z_label = torch.Tensor(z_label).to(self.device)    \n",
    "\n",
    "                    gen_alt4 = self.gen(z_fake, z_label)\n",
    "\n",
    "                    plt.figure(epoch)\n",
    "                    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "                    ax.cla()\n",
    "                    ax.imshow(gen_alt3.data.cpu().numpy()[0], cmap='gray')\n",
    "\n",
    "                    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "                    ax.cla()\n",
    "                    ax.imshow(gen_alt4.data.cpu().numpy()[0], cmap='gray')            \n",
    "                    plt.show()      \n",
    "\n",
    "            ############        save per 1000 epoch      #######################\n",
    "            if (epoch+1) % step_save_data == 0:\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    generated_3alt = []\n",
    "                    generated_4alt = []                     \n",
    "                    for _ in range(iteration_generator):  \n",
    "                       ############        num_alternative = 3      #######################\n",
    "                        z_fake = torch.randn(self.batch_size, self.dim_z, 1, 1).to(self.device)\n",
    "                        z_label = np.zeros([self.batch_size, 1]) + 0\n",
    "                        z_label = one_hot(z_label, self.num_class).reshape([self.batch_size, self.num_class, 1, 1])\n",
    "                        z_label = torch.Tensor(z_label).to(self.device)    \n",
    "                        gen_alt3 = self.gen(z_fake, z_label)\n",
    "                        generated_3alt.append(gen_alt3.data.cpu().numpy().reshape([self.batch_size, self.dim_height, self.dim_width]))\n",
    "\n",
    "                        ############        num_alternative = 4      #######################\n",
    "                        z_fake = torch.randn(self.batch_size, self.dim_z, 1, 1).to(self.device)\n",
    "                        z_label = np.zeros([self.batch_size, 1]) + 1\n",
    "                        z_label = one_hot(z_label, self.num_class).reshape([self.batch_size, self.num_class, 1, 1])\n",
    "                        z_label = torch.Tensor(z_label).to(self.device)    \n",
    "                        gen_alt4 = self.gen(z_fake, z_label)\n",
    "                        generated_4alt.append(gen_alt4.data.cpu().numpy().reshape([self.batch_size, self.dim_height, self.dim_width]))\n",
    "\n",
    "                    generated_3alt = np.array(generated_3alt).reshape([iteration_generator*self.batch_size, self.dim_height, self.dim_width])\n",
    "                    gen_alt3_ori = resize_to_ori(generated_3alt, np.math.factorial(6), 30, 24, np.math.factorial(3), self.batch_size, iteration_generator)\n",
    "                    gen_alt3_pd = pd.DataFrame(gen_alt3_ori, columns = ['ABC', 'ACB', 'BAC', 'BCA', 'CAB', 'CBA'])\n",
    "                    gen_alt3_pd.to_csv(generated_path + 'generated_atl3_' + str(epoch) + '.csv')                    \n",
    "\n",
    "                    generated_4alt = np.array(generated_4alt).reshape([iteration_generator*self.batch_size, self.dim_height, self.dim_width])     \n",
    "                    gen_alt4_ori = resize_to_ori(generated_4alt, np.math.factorial(6), 30, 24, np.math.factorial(4), self.batch_size, iteration_generator)\n",
    "                    gen_alt4_pd = pd.DataFrame(gen_alt4_ori, columns = ['ABCD', 'ACBD', 'BACD', 'BCAD', 'CABD', 'CBAD', 'DABC',\n",
    "                           'DACB', 'DBAC', 'DBCA', 'DCAB', 'DCBA', 'ADBC', 'ADCB', 'BDAC', 'BDCA',\n",
    "                           'CDAB', 'CDBA', 'ABDC', 'ACDB', 'BADC', 'BCDA', 'CADB', 'CBDA'])\n",
    "                    gen_alt4_pd.to_csv(generated_path + 'generated_atl4_' + str(epoch) + '.csv')   \n",
    "\n",
    "            time_end_epoch = time.time()\n",
    "            print('Time cost in one epoch', time_end_epoch - time_start_epoch,'s')         \n",
    "\n",
    "        ###########        save      #######################\n",
    "        torch.save(self.gen, saver_path + 'gen.pkl')\n",
    "        torch.save(self.dis, saver_path + 'dis.pkl')\n",
    "        print('save success')    \n",
    "\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        time_end=time.time()\n",
    "        print('Total Time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8f195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = election_GAN(\n",
    "                num_samples = data_alt_3_4.shape[0],\n",
    "                dim_height = data_alt_3_4.shape[1],\n",
    "                dim_width = data_alt_3_4.shape[2],\n",
    "                dim_z = 128,\n",
    "                num_class = label_alt_onehot.shape[-1],\n",
    "                batch_size = batch_size,\n",
    "                lambda_gp = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d356d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization start!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18420\\535905368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdata_alt4_ori\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_alt4_ori\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mMAE_train_train_alt3_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAE_train_train_alt3_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mMAE_train_train_alt4_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMAE_train_train_alt4_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18420\\1750313080.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self, x_train, y_train, dataloder_num_workers, train_epoch, step_valid, step_save_data, iteration_generator, n_critic, data_alt3_ori, data_alt4_ori, MAE_train_train_alt3_mean, MAE_train_train_alt4_mean)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;34m'''#############        Discriminator       #######################'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[0mz_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                 \u001b[0mx_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[0mfake_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[0mreal_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18420\\1268901788.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, label)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "model.train_model(\n",
    "    x_train = data_alt_3_4,     \n",
    "    y_train = label_alt_onehot,     \n",
    "    dataloder_num_workers = 1,\n",
    "    train_epoch = 3,  #17000\n",
    "    step_valid = 1, #50\n",
    "    step_save_data = 1000, #1000\n",
    "    iteration_generator = (2000//batch_size) + 1, # 2000 samples \n",
    "    n_critic = 5, #5\n",
    "    data_alt3_ori = data_alt3_ori,\n",
    "    data_alt4_ori = data_alt4_ori,\n",
    "    MAE_train_train_alt3_mean = MAE_train_train_alt3_mean,\n",
    "    MAE_train_train_alt4_mean = MAE_train_train_alt4_mean,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb2e2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_train_hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c967b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b7e89",
   "metadata": {},
   "source": [
    "# Show generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_trained = torch.load(saver_path + 'gen.pkl')\n",
    "\n",
    "# ############        num_alternative = 3      #######################\n",
    "# z_fake = torch.randn(batch_size, dim_z, 1, 1).to(device)\n",
    "# z_label = np.zeros([batch_size, 1]) + 0\n",
    "# z_label = one_hot(z_label, num_class).reshape([batch_size, num_class, 1, 1])\n",
    "# z_label = torch.Tensor(z_label).to(device)    \n",
    "\n",
    "# gen_alt3 = gen_trained(z_fake, z_label)\n",
    "# ############        num_alternative = 4      #######################\n",
    "# z_fake = torch.randn(batch_size, dim_z, 1, 1).to(device)\n",
    "# z_label = np.zeros([batch_size, 1]) + 1\n",
    "# z_label = one_hot(z_label, num_class).reshape([batch_size, num_class, 1, 1])\n",
    "# z_label = torch.Tensor(z_label).to(device)    \n",
    "\n",
    "# gen_alt4 = gen_trained(z_fake, z_label)\n",
    "\n",
    "# plt.figure(epoch)\n",
    "# fig, ax = plt.subplots(figsize=(3, 3))\n",
    "# ax.cla()\n",
    "# ax.imshow(gen_alt3.data.cpu().numpy()[0], cmap='gray')\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(3, 3))\n",
    "# ax.cla()\n",
    "# ax.imshow(gen_alt4.data.cpu().numpy()[0], cmap='gray')            \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e414c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
