{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ed5f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WIN10\\anaconda3\\envs\\tf1.12\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\WIN10\\anaconda3\\envs\\tf1.12\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\WIN10\\anaconda3\\envs\\tf1.12\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\WIN10\\anaconda3\\envs\\tf1.12\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\WIN10\\anaconda3\\envs\\tf1.12\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\WIN10\\anaconda3\\envs\\tf1.12\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os, time, itertools, imageio, pickle, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from utils import one_hot, resize_to_ori_calMRE, resize_to_ori\n",
    "# from Kmeans_sampling import Kmeans\n",
    "\n",
    "tf.reset_default_graph() \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea24567",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'election_GAN/'\n",
    "gen_results = 'generated_results/'\n",
    "\n",
    "model = 'model_'+'.ckpt'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "if not os.path.isdir(folder + gen_results):\n",
    "    os.mkdir(folder + gen_results)\n",
    "\n",
    "# save ckpt\n",
    "saver_path = os.path.join(folder, model)\n",
    "\n",
    "# read ckpt\n",
    "restore_path = os.path.join(folder)\n",
    "\n",
    "# save generated data\n",
    "generated_path = os.path.join(folder + gen_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffeddad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 24, 30)\n",
      "(1000, 24, 30)\n",
      "(2000, 24, 30)\n"
     ]
    }
   ],
   "source": [
    "img_width = 30\n",
    "img_height = 24\n",
    "\n",
    "data_alt3_all = pd.read_csv('./data/netflix_data_3alt_resize.csv')\n",
    "data_alt3 = data_alt3_all.iloc[:1000,1:].values\n",
    "data_alt3_val = data_alt3_all.iloc[1000:2000,1:].values\n",
    "\n",
    "data_alt3 = data_alt3.reshape([-1, img_height, img_width])\n",
    "print(data_alt3.shape)\n",
    "\n",
    "##################################\n",
    "data_alt4_all = pd.read_csv('./data/netflix_data_4alt_resize.csv')\n",
    "data_alt4 = data_alt4_all.iloc[:1000,1:].values\n",
    "data_alt4_val = data_alt4_all.iloc[1000:2000,1:].values\n",
    "\n",
    "data_alt4 = data_alt4.reshape([-1, img_height, img_width])\n",
    "print(data_alt4.shape)\n",
    "\n",
    "data_alt_3_4 = np.concatenate( (data_alt3, data_alt4), axis = 0)\n",
    "print(data_alt_3_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f16811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "label_alt3 = np.zeros([data_alt3.shape[0]])\n",
    "label_alt4 = np.zeros([data_alt4.shape[0]]) + 1\n",
    "label_alt_3_4 = np.concatenate( (label_alt3,label_alt4), axis = 0)\n",
    "\n",
    "label_alt_onehot = one_hot(label_alt_3_4, 1 + 1)   \n",
    "print(label_alt_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4647ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n",
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "img_size = np.math.factorial(6)\n",
    "img_width = 30\n",
    "img_height = 24\n",
    "ori_size = np.math.factorial(3)\n",
    "\n",
    "data_alt3_ori = resize_to_ori_calMRE(data_alt3, img_size, img_width, img_height, ori_size)\n",
    "data_alt3_val_ori = resize_to_ori_calMRE(data_alt3_val, img_size, img_width, img_height, ori_size)\n",
    "print(data_alt3_ori.shape)\n",
    "print(data_alt3_val_ori.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8135b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 24)\n",
      "(1000, 24)\n"
     ]
    }
   ],
   "source": [
    "img_size = np.math.factorial(6)\n",
    "img_width = 30\n",
    "img_height = 24\n",
    "ori_size = np.math.factorial(4)\n",
    "\n",
    "data_alt4_ori = resize_to_ori_calMRE(data_alt4, img_size, img_width, img_height, ori_size)\n",
    "data_alt4_val_ori = resize_to_ori_calMRE(data_alt4_val, img_size, img_width, img_height, ori_size)\n",
    "print(data_alt4_ori.shape)\n",
    "print(data_alt4_val_ori.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e17e471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta3_RE = []\n",
    "delta4_RE = []\n",
    "for i in range(len(data_alt3_ori)):\n",
    "    delta3_set = []\n",
    "    delta4_set = []\n",
    "    for j in range(len(data_alt3_val_ori)):\n",
    "        delta3 = np.sum(np.square(data_alt3_ori[i] - data_alt3_val_ori[j]))\n",
    "        delta4 = np.sum(np.square(data_alt4_ori[i] - data_alt4_val_ori[j]))        \n",
    "        delta3_set.append(delta3)\n",
    "        delta4_set.append(delta4)\n",
    "    delta3_RE.append(min(delta3_set))\n",
    "    delta4_RE.append(min(delta4_set))\n",
    "    \n",
    "MREvalue_val_alt3 = np.mean(delta3_RE) # train and val \n",
    "MREvalue_val_alt4 = np.mean(delta4_RE) # trani and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb6406c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.cla()\n",
    "# ax.imshow(np.reshape(data_alt3[2], (data_alt3.shape[1], data_alt3.shape[2])), cmap='gray')\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# ax.cla()\n",
    "# ax.imshow(np.reshape(data_alt4[99], (data_alt3.shape[1], data_alt3.shape[2])), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6034b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(data_alt_3_4)\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(label_alt_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef3b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class election_GAN(object):\n",
    "    def __init__(self,\n",
    "                num_samples = None,\n",
    "                dim_height = None,\n",
    "                dim_width = None,\n",
    "                dim_z = None,\n",
    "                num_class = None,\n",
    "                batch_size = None,\n",
    "                _reuse = None,\n",
    "                MemorizationPenalty_start = None,\n",
    "                ):\n",
    "        \n",
    "        # Definition Params:\n",
    "        self.num_samples = num_samples  \n",
    "        self.dim_height = dim_height    \n",
    "        self.dim_width = dim_width  \n",
    "        self.dim_z = dim_z    \n",
    "        self.num_class = num_class      \n",
    "        self.batch_size = batch_size \n",
    "        self.MemorizationPenalty_start = MemorizationPenalty_start\n",
    "\n",
    "        # Define Network Input:\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, self.dim_height, self.dim_width, 1))\n",
    "        self.Z = tf.placeholder(tf.float32, shape=(None, 1, 1, self.dim_z))\n",
    "        self.Y_label = tf.placeholder(tf.float32, shape=(None, 1, 1, self.num_class))\n",
    "        self.Y_fill = tf.placeholder(tf.float32, shape=(None, self.dim_height, self.dim_width, self.num_class))\n",
    "        self.isTrain = tf.placeholder(dtype=tf.bool)\n",
    "        self.keep_prob_feed = tf.placeholder(tf.float32)\n",
    "        self.global_step = tf.Variable(0, trainable = False)\n",
    "        self.MREvalue_val_alt3 = tf.placeholder(tf.float32)\n",
    "        self.MREvalue_val_alt4 = tf.placeholder(tf.float32)\n",
    "        self.MRE_val_index = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "        self.MRE_alt3_ori = tf.placeholder(tf.float32, shape=(None, 6))\n",
    "        self.MRE_alt4_ori = tf.placeholder(tf.float32, shape=(None, 24))\n",
    "        self.MemorizationPenalty_number = tf.Variable(0, trainable = False)\n",
    "        self.n_critic = tf.Variable(0, trainable = False)\n",
    "        \n",
    "        # Network:\n",
    "        self._GEN(self.Z, self.Y_label, self.keep_prob_feed, self.isTrain, _reuse)\n",
    "        \n",
    "        self._DIS(self.X, self.Y_fill, self.keep_prob_feed, self.isTrain, _reuse)\n",
    "            \n",
    "        with tf.variable_scope('object_cost_function', reuse=tf.AUTO_REUSE):\n",
    "            self._object_cost_function() \n",
    "        \n",
    "    def _GEN(self, Z, Y_label, keep_prob_feed, isTrain=True, _reuse=False):\n",
    "\n",
    "        with tf.variable_scope(\"GEN\", reuse=_reuse):\n",
    "            dim = 128\n",
    "\n",
    "            # concat layer\n",
    "            Z_ = tf.concat([Z, Y_label], 3)  #(batch_szie, 1, 1, dim_z + num_class)\n",
    "            Z_ = tf.reshape(Z_, (-1, self.dim_z + self.num_class))        \n",
    "\n",
    "            # FCN \n",
    "            hidden = tf.layers.dense(Z_, units = 2*2*3*dim)\n",
    "#             hidden = tf.layers.batch_normalization(hidden, training=isTrain)\n",
    "            hidden = tf.nn.relu(hidden)\n",
    "            hidden = tf.reshape(hidden, (-1, 2, 2, 3*dim)) \n",
    "\n",
    "            # CNN 1 \n",
    "            hidden = tf.layers.conv2d_transpose(hidden, 2*dim, [3, 3], strides=(1, 2), padding='valid')\n",
    "#             hidden = tf.layers.batch_normalization(hidden, training=isTrain)\n",
    "            hidden = tf.nn.relu(hidden)\n",
    "\n",
    "            # CNN 2 \n",
    "            hidden = tf.layers.conv2d_transpose(hidden, 1*dim, [3, 3], strides=(3, 3), padding='same')\n",
    "#             hidden = tf.layers.batch_normalization(hidden, training=isTrain)\n",
    "            hidden = tf.nn.relu(hidden)     \n",
    "\n",
    "            # CNN 3 \n",
    "            hidden = tf.layers.conv2d_transpose(hidden, 1, [3, 3], strides=(2, 2), padding='same')         \n",
    "            output = hidden\n",
    "\n",
    "            return output     \n",
    "    \n",
    "    def _DIS(self, X, Y_fill, keep_prob_feed, isTrain=True, _reuse=False):\n",
    "\n",
    "        with tf.variable_scope(\"DIS\", reuse=_reuse):\n",
    "            dim = 128\n",
    "            leak = 0.2\n",
    "            # concat layer\n",
    "            X_ = tf.concat([X, Y_fill], 3)  #(batch_size, dim_height, dim_width, channel + num_class)\n",
    "\n",
    "            # CNN 1 \n",
    "            hidden = tf.layers.conv2d(X_, 1*dim, [4, 5], strides=(2, 2), padding='same', use_bias=False)\n",
    "            hidden = ((0.5 * (1 + leak)) * hidden) + ((0.5 * (1 - leak)) * tf.abs(hidden)) #lrelu\n",
    "\n",
    "            # CNN 2 \n",
    "            hidden = tf.layers.conv2d(hidden, 2*dim, [4, 5], strides=(2, 2), padding='same', use_bias=False)\n",
    "            hidden = ((0.5 * (1 + leak)) * hidden) + ((0.5 * (1 - leak)) * tf.abs(hidden)) #lrelu\n",
    "\n",
    "            # CNN 3\n",
    "            hidden = tf.layers.conv2d(hidden, 2*dim, [4, 5], strides=(2, 2), padding='same', use_bias=False)\n",
    "            hidden = ((0.5 * (1 + leak)) * hidden) + ((0.5 * (1 - leak)) * tf.abs(hidden)) #lrelu\n",
    "\n",
    "            # Flatten layer\n",
    "            hidden = tf.layers.flatten(hidden)        \n",
    "            score = tf.layers.dense(hidden, units = 1)\n",
    "            score = tf.reshape(score, (-1, 1))          \n",
    "\n",
    "            return score\n",
    "    \n",
    "                        \n",
    "    def _resize_fault3(self, x, img_size = np.math.factorial(6), ori_size = np.math.factorial(3)):  \n",
    "        x = tf.reshape(x, (self.dim_height*self.dim_width,))  \n",
    "        cell_size = int(img_size//ori_size)\n",
    "        count = tf.constant(0) \n",
    "        num_iter = tf.constant(int(x.shape[0] // cell_size))  \n",
    "        \n",
    "        dat = tf.Variable([])\n",
    "        dat_ = tf.zeros([6,])\n",
    "        def cond(count, num_iter, dat):\n",
    "            return  count < num_iter\n",
    "        def body(count, num_iter, dat):\n",
    "            k = x[(count)*cell_size:(count+1)*cell_size]\n",
    "            res = tf.reduce_mean(k)\n",
    "            dat = tf.concat([dat, [res]], 0)\n",
    "    \n",
    "            count = count + 1\n",
    "            return count, num_iter, dat\n",
    "        count, num_iter, dat = tf.while_loop(cond, body, [count, num_iter, dat]\n",
    "        , shape_invariants=[count.get_shape(), num_iter.get_shape(), tf.TensorShape([None,])])      \n",
    "\n",
    "        dat_ = dat + dat_\n",
    "        \n",
    "        return tf.reshape(dat_, (1,6))\n",
    "    \n",
    "    def _resize_fault4(self, x, img_size = np.math.factorial(6), ori_size = np.math.factorial(4)):\n",
    "        x = tf.reshape(x, (self.dim_height*self.dim_width,))  \n",
    "        cell_size = int(img_size//ori_size)\n",
    "        count = tf.constant(0) \n",
    "        num_iter = tf.constant(int(x.shape[0] // cell_size))  \n",
    "        \n",
    "        dat = tf.Variable([])\n",
    "        dat_ = tf.zeros([24,])\n",
    "        def cond(count, num_iter, dat):\n",
    "            return  count < num_iter\n",
    "        def body(count, num_iter, dat):\n",
    "            k = x[(count)*cell_size:(count+1)*cell_size]\n",
    "            res = tf.reduce_mean(k)\n",
    "            dat = tf.concat([dat, [res]], 0)\n",
    "\n",
    "            count = count + 1\n",
    "            return count, num_iter, dat\n",
    "        count, num_iter, dat = tf.while_loop(cond, body, [count, num_iter, dat]\n",
    "        , shape_invariants=[count.get_shape(), num_iter.get_shape(), tf.TensorShape([None,])])         \n",
    "        \n",
    "        dat_ = dat + dat_\n",
    "\n",
    "        return tf.reshape(dat_, (1,24))    \n",
    "    \n",
    "    def _cal_MRE_and_delta_sum1(self, x):\n",
    "        \n",
    "        with tf.variable_scope(\"cal_MRE_and_delta_sum1\", reuse=False):\n",
    "            self.fake_output_mre = tf.reshape(x, (-1, self.dim_height*self.dim_width)) \n",
    "\n",
    "            ''' pick alt3 '''\n",
    "            count = tf.Variable(0, name='count3') \n",
    "            num_iter = tf.constant(self.batch_size, name='num_iter3') \n",
    "            resize_gen = tf.zeros([1,6], name='resize_gen3')\n",
    "            def cond_1(count, num_iter, resize_gen):\n",
    "                return count < num_iter\n",
    "            def body_1(count, num_iter, resize_gen):\n",
    "                resize3 = lambda: self._resize_fault3(self.fake_output_mre[count])\n",
    "                resize4 = lambda: 100 * tf.constant([1]*6, shape=[1,6], dtype=tf.float32)\n",
    "                resize_result = tf.cond(tf.reduce_mean(self.MRE_val_index[count]) > 0, resize4, resize3)\n",
    "                resize_gen = tf.concat([resize_gen, resize_result], 0)\n",
    "\n",
    "                count = count + 1\n",
    "                return count, num_iter, resize_gen\n",
    "            count, num_iter, resize_gen = tf.while_loop(cond_1, body_1, [count, num_iter, resize_gen]\n",
    "                , shape_invariants=[count.get_shape(), num_iter.get_shape(), tf.TensorShape([None, None])])     \n",
    "            resize_gen_alt3 = resize_gen[1:, :]\n",
    "\n",
    "\n",
    "            ''' pick alt4 '''\n",
    "            count = tf.constant(0) \n",
    "            num_iter = tf.constant(self.batch_size)  \n",
    "            resize_gen = tf.zeros([1,24])\n",
    "            def cond_2(count, num_iter, resize_gen):\n",
    "                return  count < num_iter\n",
    "            def body_2(count, num_iter, resize_gen):\n",
    "                resize3 = lambda: 100 * tf.constant([1]*24, shape=[1,24], dtype=tf.float32)\n",
    "                resize4 = lambda: self._resize_fault4(self.fake_output_mre[count])\n",
    "                resize_result = tf.cond(tf.reduce_mean(self.MRE_val_index[count]) > 0, resize4, resize3)\n",
    "                resize_gen = tf.concat([resize_gen, resize_result], 0)\n",
    "\n",
    "                count = count + 1\n",
    "                return count, num_iter, resize_gen\n",
    "            count, num_iter, resize_gen = tf.while_loop(cond_2, body_2, [count, num_iter, resize_gen]\n",
    "                , shape_invariants=[count.get_shape(), num_iter.get_shape(), tf.TensorShape([None, None])])     \n",
    "            resize_gen_alt4 = resize_gen[1:, :]\n",
    "\n",
    "            ''' calculate MRE '''\n",
    "            count_out = tf.constant(0) \n",
    "            num_iter_out = tf.constant(int(self.num_samples//2))  \n",
    "            delta3_RE = tf.Variable([])\n",
    "            delta4_RE = tf.Variable([])\n",
    "\n",
    "            def cond_3(count_out, num_iter_out, delta3_RE, delta4_RE):\n",
    "                return  count_out < num_iter_out\n",
    "            def body_3(count_out, num_iter_out, delta3_RE, delta4_RE):\n",
    "\n",
    "                delta3_set = tf.Variable([])\n",
    "                delta4_set = tf.Variable([])\n",
    "\n",
    "                count_in = tf.constant(0) \n",
    "                num_iter_in = tf.constant(self.batch_size)              \n",
    "                def cond_4(count_in, num_iter_in, delta3_set, delta4_set):\n",
    "                    return  count_in < num_iter_in\n",
    "                def body_4(count_in, num_iter_in, delta3_set, delta4_set):\n",
    "                    delta3 = tf.reduce_sum(tf.square(tf.subtract(self.MRE_alt3_ori[count_out], resize_gen_alt3[count_in])))\n",
    "                    delta4 = tf.reduce_sum(tf.square(tf.subtract(self.MRE_alt4_ori[count_out], resize_gen_alt4[count_in])))\n",
    "                    delta3_set = tf.concat([delta3_set, [delta3]], 0)\n",
    "                    delta4_set = tf.concat([delta4_set, [delta4]], 0)\n",
    "\n",
    "                    count_in = count_in + 1\n",
    "                    return count_in, num_iter_in, delta3_set, delta4_set\n",
    "                count_in, num_iter_in, delta3_set, delta4_set = tf.while_loop(cond_4, body_4, \n",
    "                    [count_in, num_iter_in, delta3_set, delta4_set]\n",
    "                    , shape_invariants = [count_in.get_shape(), num_iter_in.get_shape(),\n",
    "                                          tf.TensorShape([None,]), tf.TensorShape([None,]) ]) \n",
    "\n",
    "                delta3_RE = tf.concat([delta3_RE, [tf.reduce_min(tf.stack(delta3_set))]], 0)\n",
    "                delta4_RE = tf.concat([delta4_RE, [tf.reduce_min(tf.stack(delta4_set))]], 0)            \n",
    "\n",
    "                count_out = count_out + 1\n",
    "                return count_out, num_iter_out, delta3_RE, delta4_RE\n",
    "            count_out, num_iter_out, delta3_RE, delta4_RE = tf.while_loop(cond_3, body_3, \n",
    "                [count_out, num_iter_out, delta3_RE, delta4_RE]\n",
    "                , shape_invariants=[count_out.get_shape(), num_iter_out.get_shape()\n",
    "                                    , tf.TensorShape([None,]), tf.TensorShape([None,]) ])     \n",
    "\n",
    "            MRE3 = tf.reduce_mean(delta3_RE)\n",
    "            MRE4 = tf.reduce_mean(delta4_RE)\n",
    "\n",
    "            MRE3_norm = tf.div(tf.abs(tf.subtract(self.MREvalue_val_alt3, MRE3)), self.MREvalue_val_alt3)\n",
    "            MRE4_norm = tf.div(tf.abs(tf.subtract(self.MREvalue_val_alt4, MRE4)), self.MREvalue_val_alt4)             \n",
    "\n",
    "            '''restrict all ranking sum to 1'''\n",
    "            with tf.variable_scope(\"sum1\", reuse=False):\n",
    "                count_sum1 = tf.constant(0) \n",
    "                num_iter_sum1 = tf.constant(self.batch_size)  \n",
    "                \n",
    "                resize_gen_sum1 = tf.Variable([])\n",
    "                def cond_sum1(count_sum1, num_iter_sum1, resize_gen_sum1):\n",
    "                    return count_sum1 < num_iter_sum1\n",
    "                def body_sum1(count_sum1, num_iter_sum1, resize_gen_sum1):\n",
    "                    resize3 = lambda: tf.reduce_sum(self._resize_fault3(self.fake_output_mre[count_sum1]))\n",
    "                    resize4 = lambda: tf.reduce_sum(self._resize_fault4(self.fake_output_mre[count_sum1]))\n",
    "                    resize_result = tf.cond(tf.reduce_mean(self.MRE_val_index[count_sum1]) > 0, resize4, resize3)\n",
    "                    resize_gen_sum1 = tf.concat([resize_gen_sum1, [resize_result]], 0)\n",
    "\n",
    "                    count_sum1 = count_sum1 + 1\n",
    "                    return count_sum1, num_iter_sum1, resize_gen_sum1\n",
    "                count_sum1, num_iter_sum1, resize_gen_sum1 = tf.while_loop(cond_sum1, body_sum1,\n",
    "                    [count_sum1, num_iter_sum1, resize_gen_sum1]\n",
    "                    , shape_invariants=[count_sum1.get_shape(), num_iter_sum1.get_shape(), tf.TensorShape([None,])])     \n",
    "\n",
    "                sum1 = tf.constant([1]*self.batch_size, shape=[self.batch_size,], dtype=tf.float32)\n",
    "                rank_delta_sum1 = tf.reduce_sum(tf.abs(tf.subtract(resize_gen_sum1, sum1)))        \n",
    "\n",
    "                rank_delta_sum1_ = tf.zeros([1,])\n",
    "                rank_delta_sum1_ = rank_delta_sum1_ + rank_delta_sum1\n",
    "                \n",
    "        return MRE3_norm, MRE4_norm, tf.reduce_mean(rank_delta_sum1_)\n",
    "\n",
    "        \n",
    "    def _object_cost_function(self):\n",
    "        # networks : generator\n",
    "        self.fake_output = self._GEN(self.Z, self.Y_label, self.keep_prob_feed, self.isTrain, _reuse=False)\n",
    "\n",
    "        # networks : discriminator\n",
    "        real_score = self._DIS(self.X, self.Y_fill, self.keep_prob_feed, self.isTrain, _reuse=False)\n",
    "        fake_score = self._DIS(self.fake_output, self.Y_fill, self.keep_prob_feed, self.isTrain, _reuse=True)\n",
    "\n",
    "        # Mean Recovery Error (MRE): calculate MRE after epoch is over 2000\n",
    "        self.MRE_alt3_ori = tf.cast(self.MRE_alt3_ori, dtype=tf.float32)\n",
    "        self.MRE_alt4_ori = tf.cast(self.MRE_alt4_ori, dtype=tf.float32)\n",
    "        self.fake_output = tf.cast(self.fake_output, dtype=tf.float32)\n",
    "        self.MREvalue_val_alt3 = tf.cast(self.MREvalue_val_alt3, dtype=tf.float32)\n",
    "        self.MREvalue_val_alt4 = tf.cast(self.MREvalue_val_alt4, dtype=tf.float32)\n",
    "        self.MRE_val_index = tf.cast(self.MRE_val_index, dtype=tf.float32)\n",
    "                \n",
    "        def f1(): return self._cal_MRE_and_delta_sum1(self.fake_output)\n",
    "        def f2(): return tf.cast(0, dtype=tf.float32), tf.cast(0, dtype=tf.float32), tf.cast(0, dtype=tf.float32)\n",
    "        self.MRE3_norm, self.MRE4_norm, self.rank_delta_sum1 = tf.cond(\n",
    "            tf.greater(self.global_step, self.MemorizationPenalty_start), f1, f2)\n",
    "        \n",
    "        '''define the loss ops'''\n",
    "        self.D_loss = tf.reduce_mean(-real_score + fake_score)\n",
    "#         self.G_loss = tf.reduce_mean(-fake_score) + 0.5*(self.MRE3_norm + self.MRE4_norm) + 0.5*self.rank_delta_sum1\n",
    "                \n",
    "        def f3(): return tf.reduce_mean(-fake_score)\n",
    "        def f4(): return tf.reduce_mean(-fake_score) + 0.5*(self.MRE3_norm + self.MRE4_norm) + 0.5*self.rank_delta_sum1\n",
    "        self.G_loss = tf.cond(tf.mod(self.n_critic, self.MemorizationPenalty_number) > 0, f3, f4)        \n",
    "        \n",
    "            \n",
    "        ################  Gradient penalty  ################\n",
    "        LAMBDA = 10\n",
    "        alpha = tf.random_uniform(shape=[self.batch_size, 1], minval=0.,maxval=1.)  \n",
    "\n",
    "        real_data = tf.reshape(self.X, (self.batch_size, self.dim_height*self.dim_width))    \n",
    "        fake_data = tf.reshape(self.fake_output, (self.batch_size, self.dim_height*self.dim_width))    \n",
    "\n",
    "        interpolates = (alpha * real_data + ((1 - alpha) * fake_data))    \n",
    "        interpolates_d = tf.reshape(interpolates, (self.batch_size, self.dim_height, self.dim_width, 1))  \n",
    "        interpolates_d = self._DIS(interpolates_d, self.Y_fill, self.keep_prob_feed, self.isTrain, _reuse=True)                   \n",
    "\n",
    "        gradients = tf.gradients(interpolates_d, [interpolates])[0]   \n",
    "        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))  \n",
    "        gradient_penalty = tf.reduce_mean((slopes-1.)**2) \n",
    "        self.D_loss = self.D_loss + LAMBDA*gradient_penalty\n",
    "        ###############  Gradient penalty  ################\n",
    "\n",
    "\n",
    "        # define the optimizer ops\n",
    "        self.T_vars = tf.trainable_variables()\n",
    "#         self.D_vars = [var for var in self.T_vars if var.name.startswith('DIS')]\n",
    "#         self.G_vars = [var for var in self.T_vars if var.name.startswith('GEN')]\n",
    "        self.D_vars = [var for var in self.T_vars if 'DIS' in var.name]\n",
    "        self.G_vars = [var for var in self.T_vars if 'DIS' not in var.name]\n",
    "                \n",
    "        learning_rate = 0.0001\n",
    "        # define the update ops to run batch normalization\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "#             self.D_optim = tf.train.RMSPropOptimizer(learning_rate).minimize(self.D_loss, var_list=self.D_vars)\n",
    "#             self.G_optim = tf.train.RMSPropOptimizer(learning_rate).minimize(self.G_loss, var_list=self.G_vars)\n",
    "            self.D_optim = tf.train.AdamOptimizer(learning_rate, beta1=0.5, beta2=0.9).minimize(self.D_loss, var_list=self.D_vars)\n",
    "            self.G_optim = tf.train.AdamOptimizer(learning_rate, beta1=0.5, beta2=0.9).minimize(self.G_loss, var_list=self.G_vars)\n",
    "            \n",
    "            \n",
    "    def train_model(self,\n",
    "                    x_train = None,     \n",
    "                    y_train = None,     \n",
    "                    keep_prob = None,\n",
    "                    train_epoch = None, \n",
    "                    n_critic = None,\n",
    "                    step_valid = 50,\n",
    "                    step_save_data = 1000,\n",
    "                    iteration_generator = 50,\n",
    "                    MREvalue_val_alt3 = None,\n",
    "                    MREvalue_val_alt4 = None,\n",
    "                    MRE_alt3_ori = None,\n",
    "                    MRE_alt4_ori = None,\n",
    "                    MemorizationPenalty_number = None,\n",
    "                   ): \n",
    "        \n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        session_config = tf.ConfigProto(gpu_options = tf.GPUOptions(allow_growth=True))\n",
    "        with tf.Session(config = session_config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print('Optimization start!')\n",
    "            \n",
    "            for epoch in range(train_epoch):\n",
    "                G_losses = []\n",
    "                D_losses = []\n",
    "                \n",
    "                time_start_epoch = time.time()\n",
    "                \n",
    "                for i in range(len(x_train) // self.batch_size): # num_samples / batch_size\n",
    "                    '''#############        Discriminator       #######################'''\n",
    "                    x_ = x_train[i*self.batch_size: (i+1)*self.batch_size] \n",
    "                    x_ = x_.reshape((self.batch_size, self.dim_height, self.dim_width, 1))   #(batch_size, dim_height, dim_width, 1)\n",
    "                    y_label_ = y_train[i*self.batch_size:(i+1)*self.batch_size].reshape([self.batch_size, 1, 1, self.num_class])\n",
    "                    y_fill_ = y_label_ * np.ones([self.batch_size, self.dim_height, self.dim_width, self.num_class]) #(batch_szie, height, width, num_class)\n",
    "                    z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))\n",
    "\n",
    "                    loss_d, _ = sess.run([self.D_loss, self.D_optim], \n",
    "                                          feed_dict={self.X: x_, \n",
    "                                                     self.Z: z_, \n",
    "                                                     self.Y_fill: y_fill_, \n",
    "                                                     self.Y_label: y_label_, \n",
    "                                                     self.keep_prob_feed: keep_prob,\n",
    "                                                     self.isTrain: True,\n",
    "                                                     self.global_step: epoch})\n",
    "                    D_losses.append(loss_d)\n",
    "\n",
    "                    '''#############        Generator          #######################'''\n",
    "                    if (i+1) % n_critic == 0:   # Train the generator every n_critic iterations\n",
    "                        z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))\n",
    "                        y_ = []\n",
    "                        for _ in range(self.batch_size): y_.append(random.randrange(0, self.num_class, self.num_class-1))  \n",
    "                        y_ = np.array(y_).reshape([self.batch_size, 1])\n",
    "        #                 y_ = np.random.randint(0, 2, (batch_size, 1))\n",
    "                        y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "                        y_fill_ = y_label_ * np.ones([self.batch_size, self.dim_height, self.dim_width, self.num_class])\n",
    "                        loss_g, _, MRE3_norm, MRE4_norm, rank_delta_sum1 = sess.run([\n",
    "                            self.G_loss, self.G_optim, self.MRE3_norm, self.MRE4_norm, self.rank_delta_sum1], \n",
    "                                              feed_dict={self.Z: z_, \n",
    "                                                         self.X: x_, \n",
    "                                                         self.Y_fill: y_fill_, \n",
    "                                                         self.Y_label: y_label_, \n",
    "                                                         self.keep_prob_feed: keep_prob,\n",
    "                                                         self.isTrain: True,\n",
    "                                                         self.MREvalue_val_alt3: MREvalue_val_alt3,\n",
    "                                                         self.MREvalue_val_alt4: MREvalue_val_alt4,\n",
    "                                                         self.MRE_val_index: y_,\n",
    "                                                         self.MRE_alt3_ori: MRE_alt3_ori,\n",
    "                                                         self.MRE_alt4_ori: MRE_alt4_ori,\n",
    "                                                         self.global_step: epoch,\n",
    "                                                         self.n_critic: n_critic,\n",
    "                                                         self.MemorizationPenalty_number: MemorizationPenalty_number,\n",
    "                                                        })\n",
    "                        G_losses.append(loss_g)\n",
    "#                         print('MRE3_norm ', MRE3_norm)\n",
    "#                         print('MRE4_norm ', MRE4_norm)\n",
    "#                         print('rank_delta_sum1 ', rank_delta_sum1)\n",
    "\n",
    "            \n",
    "            ############        print result      #######################\n",
    "                if (epoch+1) % 1 == 0:\n",
    "                    print('[%d/%d] loss_d: %.3f, loss_g: %.3f'%((epoch + 1), train_epoch, np.mean(D_losses), np.mean(G_losses)))\n",
    "                    self.train_hist['D_losses'].append(np.mean(D_losses))\n",
    "                    self.train_hist['G_losses'].append(np.mean(G_losses))\n",
    "\n",
    "            ############        valid      #######################\n",
    "                if (epoch+1) % step_valid == 0:\n",
    "                   ############        num_alternative = 3      #######################\n",
    "                    z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))   \n",
    "\n",
    "                    y_ = np.zeros([self.batch_size, 1]) + 0\n",
    "                    y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "                    y_fill_ = y_label_ * np.ones([self.batch_size, self.dim_height, self.dim_width, self.num_class])\n",
    "                    output_g_alt3 = sess.run([self.fake_output], \n",
    "                                          feed_dict={self.Z: z_, \n",
    "                                                     self.X: x_, \n",
    "                                                     self.Y_fill: y_fill_, \n",
    "                                                     self.Y_label: y_label_, \n",
    "                                                     self.keep_prob_feed: 1,\n",
    "                                                     self.isTrain: False})    \n",
    "                    output_g_alt3_ = np.array(output_g_alt3).reshape([self.batch_size, self.dim_height, self.dim_width])[0]\n",
    "\n",
    "                    ############        num_alternative = 4      #######################\n",
    "                    z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))   \n",
    "\n",
    "                    y_ = np.zeros([self.batch_size, 1]) + 1\n",
    "                    y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "                    y_fill_ = y_label_ * np.ones([self.batch_size, self.dim_height, self.dim_width, self.num_class])\n",
    "                    output_g_alt4 = sess.run([self.fake_output], \n",
    "                                          feed_dict={self.Z: z_, \n",
    "                                                     self.X: x_, \n",
    "                                                     self.Y_fill: y_fill_, \n",
    "                                                     self.Y_label: y_label_, \n",
    "                                                     self.keep_prob_feed: 1,\n",
    "                                                     self.isTrain: False})  \n",
    "                    output_g_alt4_ = np.array(output_g_alt4).reshape([self.batch_size, self.dim_height, self.dim_width])[0]\n",
    "                                     \n",
    "                    plt.figure(epoch)\n",
    "                    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "                    ax.cla()\n",
    "                    ax.imshow(np.reshape(output_g_alt3_, (self.dim_height, self.dim_width)), cmap='gray')\n",
    "\n",
    "                    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "                    ax.cla()\n",
    "                    ax.imshow(np.reshape(output_g_alt4_, (self.dim_height, self.dim_width)), cmap='gray')            \n",
    "                    plt.show()\n",
    "\n",
    "            ############        save per 1000 epoch      #######################\n",
    "                if (epoch+1) % step_save_data == 0:\n",
    "                    \n",
    "                    generated_3alt = []\n",
    "                    generated_4alt = []                     \n",
    "                    for _ in range(iteration_generator):  \n",
    "                         ############        num_alternative = 3      #######################\n",
    "                        z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))   \n",
    "                        y_ = np.zeros([self.batch_size, 1]) + 0\n",
    "                        y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "\n",
    "                        output_g_alt3 = sess.run([self.fake_output], feed_dict={self.Z: z_, self.Y_label: y_label_})    \n",
    "                        generated_3alt.append(np.array(output_g_alt3).reshape([self.batch_size, self.dim_height, self.dim_width]))\n",
    "\n",
    "                        ############        num_alternative = 4      #######################\n",
    "                        z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))   \n",
    "                        y_ = np.zeros([self.batch_size, 1]) + 1\n",
    "                        y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "\n",
    "                        output_g_alt4 = sess.run([self.fake_output], feed_dict={self.Z: z_, self.Y_label: y_label_})  \n",
    "                        generated_4alt.append(np.array(output_g_alt4).reshape([self.batch_size, self.dim_height, self.dim_width]))\n",
    "\n",
    "                    generated_3alt = np.array(generated_3alt).reshape([iteration_generator*self.batch_size, self.dim_height, self.dim_width])\n",
    "                  \n",
    "                    gen_alt3_ori = resize_to_ori(generated_3alt, np.math.factorial(6), 30, 24, np.math.factorial(3), self.batch_size, iteration_generator)\n",
    "                    gen_alt3_pd = pd.DataFrame(gen_alt3_ori, columns = ['ABC', 'ACB', 'BAC', 'BCA', 'CAB', 'CBA'])\n",
    "                    gen_alt3_pd.to_csv(generated_path + 'generated_atl3_' + str(epoch) + '.csv')                    \n",
    "                    \n",
    "                    generated_4alt = np.array(generated_4alt).reshape([iteration_generator*self.batch_size, self.dim_height, self.dim_width])     \n",
    "                    \n",
    "                    gen_alt4_ori = resize_to_ori(generated_4alt, np.math.factorial(6), 30, 24, np.math.factorial(4), self.batch_size, iteration_generator)\n",
    "                    gen_alt4_pd = pd.DataFrame(gen_alt4_ori, columns = ['ABCD', 'ACBD', 'BACD', 'BCAD', 'CABD', 'CBAD', 'DABC',\n",
    "                           'DACB', 'DBAC', 'DBCA', 'DCAB', 'DCBA', 'ADBC', 'ADCB', 'BDAC', 'BDCA',\n",
    "                           'CDAB', 'CDBA', 'ABDC', 'ACDB', 'BADC', 'BCDA', 'CADB', 'CBDA'])\n",
    "#                     print(gen_alt4_pd.shape)\n",
    "                    gen_alt4_pd.to_csv(generated_path + 'generated_atl4_' + str(epoch) + '.csv')   \n",
    "                    \n",
    "\n",
    "                time_end_epoch = time.time()\n",
    "                print('Time cost in one epoch', time_end_epoch - time_start_epoch,'s') \n",
    "                \n",
    "            ###########        save      #######################\n",
    "            saver.save(sess, saver_path)   \n",
    "            print('save success')\n",
    "\n",
    "            sess.close()\n",
    "            \n",
    "        print(\"Optimization Finished!\")\n",
    "        \n",
    "    '''loss curve'''\n",
    "    def show_train_hist(self):\n",
    "        x = range(len(self.train_hist['D_losses']))\n",
    "\n",
    "        y1 = self.train_hist['D_losses']\n",
    "        y2 = self.train_hist['G_losses']\n",
    "\n",
    "        plt.plot(x, y1, label='D_loss')\n",
    "        plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.legend(loc=4)  \n",
    "        plt.grid(True)\n",
    "        plt.tight_layout() \n",
    "        plt.title(\"Training Losses\")\n",
    "\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c99b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = data_alt_3_4.shape[0]\n",
    "dim_height = data_alt_3_4.shape[1]\n",
    "dim_width = data_alt_3_4.shape[2]\n",
    "dim_z = 128\n",
    "num_class = label_alt_onehot.shape[-1]\n",
    "batch_size = 50\n",
    "MemorizationPenalty_start = 0 #2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799334a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = election_GAN(\n",
    "                num_samples = num_samples,\n",
    "                dim_height = dim_height,\n",
    "                dim_width = dim_width,\n",
    "                dim_z = dim_z,\n",
    "                num_class = num_class,\n",
    "                batch_size = batch_size,\n",
    "                MemorizationPenalty_start = MemorizationPenalty_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c660c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization start!\n",
      "[1/2] loss_d: 2.017, loss_g: 0.725\n",
      "Time cost in one epoch 6.0449137687683105 s\n",
      "[2/2] loss_d: -2.194, loss_g: 2.646\n",
      "Time cost in one epoch 103.4290337562561 s\n",
      "save success\n",
      "Optimization Finished!\n",
      "Total Time cost 116.28422284126282 s\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "model.train_model(\n",
    "    x_train = data_alt_3_4,     \n",
    "    y_train = label_alt_onehot,     \n",
    "    keep_prob = 0.5, #0.5\n",
    "    train_epoch = 2, #17000\n",
    "    n_critic = 5,#5\n",
    "    step_valid = 50, #50\n",
    "    step_save_data = 1000, #1000\n",
    "    iteration_generator = 50,\n",
    "    MREvalue_val_alt3 = MREvalue_val_alt3,\n",
    "    MREvalue_val_alt4 = MREvalue_val_alt4,\n",
    "    MRE_alt3_ori = data_alt3_ori.reshape([-1, 6]),\n",
    "    MRE_alt4_ori = data_alt4_ori.reshape([-1, 24]),\n",
    "    MemorizationPenalty_number = 10, # penalty (num_samples (2000)//batch_size (50)//MemorizationPenalty_number(10) ) times per epoch\n",
    "    )\n",
    "\n",
    "time_end=time.time()\n",
    "print('Total Time cost',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ed8ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_train_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828aba7c",
   "metadata": {},
   "source": [
    "# Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81da2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class election_GAN_GEN(object):\n",
    "    def __init__(self,\n",
    "                dim_height = None,\n",
    "                dim_width = None,\n",
    "                dim_z = None,\n",
    "                num_class = None,\n",
    "                batch_size = None,):\n",
    "        \n",
    "        # Definition Params:\n",
    "        self.dim_height = dim_height    \n",
    "        self.dim_width = dim_width  \n",
    "        self.dim_z = dim_z    \n",
    "        self.num_class = num_class      \n",
    "        self.batch_size = batch_size  \n",
    "\n",
    "        # Define Network Input:\n",
    "        self.Z = tf.placeholder(tf.float32, shape=(None, 1, 1, self.dim_z))\n",
    "        self.Y_label = tf.placeholder(tf.float32, shape=(None, 1, 1, self.num_class))\n",
    "\n",
    "        # Network:\n",
    "        self._GEN(self.Z, self.Y_label)\n",
    "\n",
    "        # get the generated data\n",
    "        with tf.variable_scope('object_cost_function', reuse=tf.AUTO_REUSE):\n",
    "            self.call_GEN()\n",
    "        \n",
    "    def _GEN(self, Z, Y_label):            \n",
    "        keep_prob_feed = 1\n",
    "        isTrain=False \n",
    "        dim = 128\n",
    "        \n",
    "        with tf.variable_scope(\"GEN\", reuse=False):\n",
    "            # concat layer\n",
    "            Z_ = tf.concat([Z, Y_label], 3)  #(batch_szie, 1, 1, dim_z + num_class)\n",
    "            Z_ = tf.reshape(Z_, (-1, self.dim_z + self.num_class))        \n",
    "\n",
    "            # FCN \n",
    "            hidden = tf.layers.dense(Z_, units = 2*2*3*dim)\n",
    "#             hidden = tf.layers.batch_normalization(hidden, training=isTrain)\n",
    "            hidden = tf.nn.relu(hidden)\n",
    "            hidden = tf.reshape(hidden, (-1, 2, 2, 3*dim)) \n",
    "\n",
    "            # CNN 1 \n",
    "            hidden = tf.layers.conv2d_transpose(hidden, 2*dim, [3, 3], strides=(1, 2), padding='valid')\n",
    "#             hidden = tf.layers.batch_normalization(hidden, training=isTrain)\n",
    "            hidden = tf.nn.relu(hidden)\n",
    "\n",
    "            # CNN 2 \n",
    "            hidden = tf.layers.conv2d_transpose(hidden, 1*dim, [3, 3], strides=(3, 3), padding='same')\n",
    "#             hidden = tf.layers.batch_normalization(hidden, training=isTrain)\n",
    "            hidden = tf.nn.relu(hidden)     \n",
    "\n",
    "            # CNN 3 \n",
    "            hidden = tf.layers.conv2d_transpose(hidden, 1, [3, 3], strides=(2, 2), padding='same')         \n",
    "            output = hidden\n",
    "\n",
    "            return output     \n",
    "    \n",
    "    def call_GEN(self):\n",
    "        self.fake_output = self._GEN(self.Z, self.Y_label)\n",
    "\n",
    "    def GEN_model(self, path, iteration): \n",
    "    \n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(path))      \n",
    "            \n",
    "            generated_3alt = []\n",
    "            generated_4alt = []  \n",
    "            \n",
    "            for _ in range(iteration): \n",
    "                '''#############        Generator          #######################'''\n",
    "                ############        num_alternative = 3      #######################\n",
    "                z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))   \n",
    "                y_ = np.zeros([self.batch_size, 1]) + 0\n",
    "                y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "\n",
    "                output_g_alt3 = sess.run([self.fake_output], feed_dict={self.Z: z_, self.Y_label: y_label_})    \n",
    "                output_g_alt3_ = np.array(output_g_alt3).reshape([self.batch_size, self.dim_height, self.dim_width])\n",
    "                generated_3alt.append(output_g_alt3_)\n",
    "                \n",
    "                ############        num_alternative = 4      #######################\n",
    "                z_ = np.random.normal(0, 1, (self.batch_size, 1, 1, self.dim_z))   \n",
    "                y_ = np.zeros([self.batch_size, 1]) + 1\n",
    "                y_label_ = one_hot(y_, self.num_class).reshape([self.batch_size, 1, 1, self.num_class])\n",
    "\n",
    "                output_g_alt4 = sess.run([self.fake_output], feed_dict={self.Z: z_, self.Y_label: y_label_})  \n",
    "                output_g_alt4_ = np.array(output_g_alt4).reshape([self.batch_size, self.dim_height, self.dim_width])\n",
    "                generated_4alt.append(output_g_alt4_)\n",
    "\n",
    "            generated_3alt = np.array(generated_3alt).reshape([iteration*self.batch_size, self.dim_height, self.dim_width])\n",
    "            generated_4alt = np.array(generated_4alt).reshape([iteration*self.batch_size, self.dim_height, self.dim_width])\n",
    "                \n",
    "            return generated_3alt, generated_4alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e87163b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c002f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = election_GAN_GEN(\n",
    "                dim_height = dim_height,\n",
    "                dim_width = dim_width,\n",
    "                dim_z = dim_z,\n",
    "                num_class = num_class,\n",
    "                batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77d2d3",
   "metadata": {},
   "source": [
    "shape[0]: number of generated data\n",
    "\n",
    "shape[1], shape[2]: data size before resize back to original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50d5d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from election_GAN/model_.ckpt\n",
      "(2500, 24, 30)\n",
      "(2500, 24, 30)\n"
     ]
    }
   ],
   "source": [
    "iteration_generator = 50\n",
    "gen_alt3, gen_alt4 = generator.GEN_model(path = restore_path, \n",
    "                                         iteration = iteration_generator) #iteration: how many times generator is used?\n",
    "print(gen_alt3.shape) \n",
    "print(gen_alt4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b12273be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAD+CAYAAABBe3JJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYVElEQVR4nO3daWzV55UG8OfgHQPGxgbMFhOWEEIJJA6JEzpKmj1qk7RSl1SMmKYVTdSqqTQfJuqHLqraRqNJpvNhVJVM0zBqS5SUNFC1ipKGSgx7gCbsCZSyGbABsxgTwMuZD75UbmL7PNgXL2+enxRh3/vo/x7/fX1yfX3+7zV3h4hIqob0dwEiIleTmpyIJE1NTkSSpiYnIklTkxORpKnJiUjScvtysSFDhviQId331ZycHOpYbW1tYSYvLy/MtLS0hBkzo2pqbm4OMwUFBVmpiT3WxYsXs3IcALh06VKYib6/APe9Gzp0KFXTBx98EGYKCwuzchyA+/qYxwFTE3us3Nz4x5g5DvPzks1jseNrzM9DS0vLCXev6Oy+XjU5M3sAwH8ByAHwP+7+THf5IUOGYNiwYd0es7S0lFr7woULYWbs2LFh5vjx42GGbQK1tbVhZurUqWGmrq6OWm/KlClhZt++fWHm2muvpdY7cOBAmCkuLg4zzPfuxhtvpGrasWNHmLn++uvDzLZt26j1mOZ07NixMDNjxgxqPeaxUFZWlpXjMD8vAPc4HzduXJhh/gcMAA0NDWGmvr6+ywdnj39dNbMcAP8N4EEAMwE8ZmYze3o8EZGroTevyc0DsNfd97n7JQAvAXgkO2WJiGRHb5rceACHOnx+OHPbPzCzRWa2ycw2Ma/FiIhk01X/w4O7LwawGAByc3N1oayI9KnePJOrBTCxw+cTMreJiAwYvWlybwOYZmaTzSwfwJcArMhOWSIi2WG92WrJzB4C8FO0j5C84O4/6i5fUFDglZWV0TGptUeOHBlmDh8+HGZGjBgRZpqampiSUFHR6ZjOP2DGJ9j1mO/dhAkTwgwzZgJwM2JMZt68eWFm/fr1VE1VVVVh5uzZs2GGGcMAgPPnz4cZZm5t//791HrMWMfJkyfDTPRzB3DzbwBQVFQUZrZu3Rpm2DGaEydOhJkjR45sdvfqzu7r1Wty7v5HAH/szTFERK4mXdYlIklTkxORpKnJiUjS1OREJGlqciKSNDU5EUmampyIJE1NTkSS1qc7A7t7uCvsnDlzqGM1NjaGmdGjR4cZ5uoCZpNAALjmmmvCzKxZs8LMxo0bqfUOHToUZm677bYwM23aNGo95soBZiPPn//852FmwYIFVE3MtD+ziSVzRQCAcNNXgLsqoqSkhFqP+Xk4d+5cmGE3YmXU19eHmZqamjDD1A1wm7oeOXKky/v0TE5EkqYmJyJJU5MTkaSpyYlI0tTkRCRpanIikjQ1ORFJmpqciCStV9ufX6mCggKP3lm7tbWVOtb48R9598OPYIYWmQHe7gYNO2LeNZx5W0ZmC3EAOH78eJhhztOlS5eo9Zgc8/1jhrSZgVqAG85lhoGZbfABbituZrB49+7d1HrM8DjzeGEeK8zXBnBb6h89ejTMDB8+nFqPeSxs3bq1y+3P9UxORJKmJiciSVOTE5GkqcmJSNLU5EQkaWpyIpI0NTkRSZqanIgkrU93BjYz5Ofnd5thB1MZp0+fDjNFRUVhZuTIkdR6VVVVYeaVV14JM7fccgu1HiM3N/4Wv/vuu9SxHnzwwTDD7GpcXFwcZnbt2kXVNHPmzDDDDJ3efPPN1HorVqwIM8zgbXl5ObUe8/OwZcuWMHPrrbeGmQsXLlA1NTQ0hBnme5yTk0OtF/WMiJ7JiUjS1OREJGlqciKSNDU5EUmampyIJE1NTkSSpiYnIklTkxORpKnJiUjS+vSKh7a2tnAr41GjRlHHYqaumS2tma242e3P161bF2bGjBkTZg4ePEitl5eXl5UMu+X8+++/H2YqKirCTGNjY5hhvi8AcP3114eZlStXhhnmewdwtTc1NYUZdrt1Zr2SkpIwU1tbG2bq6uqompiraJi3VWCuVgGA9957j8p1pVdNzsz2A2gE0Aqgpas91kVE+ks2nsnd5e7cO2CIiPQxvSYnIknrbZNzAG+Y2WYzW5SNgkREsqm3v67Od/daMxsN4E0z2+3uqzoGMs1vEcBvrSIiki29eibn7rWZf+sB/A7AvE4yi9292t2r2TdNFhHJlh53HTMrNrPhlz8GcB+A7dkqTEQkG3rz6+oYAL8zs8vH+Y27v56VqkREssSYob1syc/P92jIs7S0lDrW0aNHw0x1dTy2x2xVfe2111I17d27N8www6tr1qyh1isrKwszQ4cODTPjxo2j1mMwg9Nr164NM1/84hep9c6ePRtm5s37yKsoH7FkyRJqvfvvvz/MMNvJM1vlA9w28DfeeGOYYQa52QHlM2fOhBlmKJwZmga4YfVVq1Zt7mpOVy+SiUjS1OREJGlqciKSNDU5EUmampyIJE1NTkSSpiYnIklTkxORpPXpMHBOTo4XFxd3m6msrKSOxeSYgeH8/PwwM3LkSKYknD59OswUFhaGGWaAF+AGRW+//fasHAfgBpn3798fZubPnx9mfv/73zMlYezYsWEmeswB7btWM5hBWGagnd3ttqamJsysX78+zDCD8Vu2bKFqmjJlSpjZuHFjmJk7dy613smTJ8PM7t27NQwsIh9PanIikjQ1ORFJmpqciCRNTU5EkqYmJyJJU5MTkaSpyYlI0tTkRCRpfXrFQ1FRkU+dOrXbzN13300da/ny5WGGORYzeV5UVETVxEzWz5kzJ8y89tpr1HqTJk0KM9F28wC3jToAnD9/Psz84Ac/CDMLFiwIM0888QRV05/+9Kcww2zFPWrUKGq9vLy8MLN06dIww1xpAwATJkwIM9OmTQszx44dCzOZ92sJMV/fU089FWZeeuklar1rrrkmzKxYsUJXPIjIx5OanIgkTU1ORJKmJiciSVOTE5GkqcmJSNLU5EQkaWpyIpK0Ph0GLiws9IkTJ3abKSkpoY41YsQIZr0wk5OTE2aGDRtG1cRsjc3UxHxtALdt+ac+9akwU1tbS61XXl4eZpgt4GfNmhVmzp07x5REPV6YbfDr6+up9Q4ePBhmZs+eHWbWrVtHrXfrrbeGGWaIl9mWnhkYBoDp06eHGeYxxQ4f5+bmhpnXX39dw8Ai8vGkJiciSVOTE5GkqcmJSNLU5EQkaWpyIpI0NTkRSZqanIgkLZ6yy6KCggJEOwO3tLRQx2J2TH3xxRfDzH333Rdmxo4dy5SE22+/Pcy8/PLLWVuP2aX24sWLYebAgQPUegsXLgwzzIAyMxD94x//mKrphz/8YZhhho+ZHZQB4Fvf+laYiR7jAD/wXVBQEGbWrl0bZr7yla+EmfXr11M1Mbsob9y4Mcx85jOfodZjdu/ujp7JiUjSwiZnZi+YWb2Zbe9wW5mZvWlmezL/ll7dMkVEeoZ5JvcigAc+dNvTAN5y92kA3sp8LiIy4IRNzt1XAWj40M2PAFiS+XgJgEezW5aISHb09A8PY9z98tYOxwCM6SpoZosALAK4F5xFRLKp13948Pa9mrrcr8ndF7t7tbtXs+81KSKSLT1tcnVmVgkAmX+5zbhERPpYT5vcCgCXh6YWAojfzl5EpB8wIyRLAawDcJ2ZHTazrwJ4BsC9ZrYHwD2Zz0VEBpzwDw/u/lgXd919pYu1traG22Oz258z2znfcccdYea6664LM6tXr2ZKwp49e8IMs633tm3bqPWKi4uzkmlo+PAfzzvHnPMhQ+JfDlauXBlmHn74YaYk3HDDDWGGufKFuUoB4LbC37t3b5hpbm6m1mN+HpjvH3M1A1M3ALz//vthhrmC5NSpU9R6bF1d0RUPIpI0NTkRSZqanIgkTU1ORJKmJiciSVOTE5GkqcmJSNLU5EQkadZ+fX3fKCws9IkTJ3abYYZXAaC2tjbMlJeXMzWFmenTp1M1vfvuu2GmqqoqzFy6dIlajzkHc+fODTOtra3UegcPHszKsZgt7isqKqiaGhsbw8znP//5MPPqq69S6zHD48zQ9PHjx6n15s+fH2aOHj0aZpjHObNVPsB9/5gt/Jm6AW6r+KVLl2529+rO7tMzORFJmpqciCRNTU5EkqYmJyJJU5MTkaSpyYlI0tTkRCRpanIikrSeviVhj7h7uCNqQUEBdSxm2DA3N/7ymEHDAwcOUDVVVlaGGWYAcvbs2dR6f/nLX8LM2bNnw0xTUxO13siRI8PM+fPnw0w0EA5wu88C3Pd469atYWbUqFHUekeOHAkzY8Z0+Q6df7dx40ZqvSlTpoQZZrfpHTt2hBl2CH3cuHFhZt26dWGGGawG+Lq6omdyIpI0NTkRSZqanIgkTU1ORJKmJiciSVOTE5GkqcmJSNLU5EQkaWpyIpK0Pr3iAQDMrNv7b775Zuo4e/fuDTM5OTlh5sKFC2Fmzpw5TEl45513wgyzHfmGDRuo9e65554ws3v3bupYjHvvvTfMPPfcc2Hmc5/7XJh55ZVXqJoef/zxMFNTUxNm2K24T548GWZ27twZZr785S9T6zFXazBX/3z6058OM8zVFQDwy1/+Msw8+eSTYWbNmjXUerNmzQozb775Zpf36ZmciCRNTU5EkqYmJyJJU5MTkaSpyYlI0tTkRCRpanIikjQ1ORFJmrl7ny2Wn5/v0dbQQ4cOpY41fvz4bJREbXtdWFhIHYvZjnz06NFhZsgQ7v89Z86cCTM33HBDmIkGtC+rra0NM8y25V/72tfCTF1dHVUTM/DNbLfODN0CwObNm8PMvHnzwgzzWAG44fG8vLwwwwyFr127lqrprrvuCjPMNvjMzwIAtLW1hZnly5dvdvfqzu4Lf5rM7AUzqzez7R1u+76Z1ZrZO5n/HqKqFRHpY8xThhcBPNDJ7f/p7nMy//0xu2WJiGRH2OTcfRWAhj6oRUQk63rzh4dvmtnWzK+zpVmrSEQki3ra5H4GYAqAOQCOAni2q6CZLTKzTWa2iXkBUUQkm3rU5Ny9zt1b3b0NwPMAuvxzkrsvdvdqd69m/2ooIpItPeo6ZtbxreI/C2B7V1kRkf4UbpppZksB3Amg3MwOA/gegDvNbA4AB7AfwNevXokiIj3Xp8PApaWlfvfdd3ebYQcET506FWaYgcsFCxaEmWPHjlE1TZgwIcy89dZbYeaTn/wktR4zwDp58uQw09raSq330EPxOGRVVVWYYXZj/u53v8uUhKeffjrMMAO1y5Yto9Z79tkuX36+ovWYYVmA25U6Nzfe4LukpCTMDBs2jCkJK1euDDOrV68OM8xO0wA3jP+Tn/yk58PAIiKDmZqciCRNTU5EkqYmJyJJU5MTkaSpyYlI0tTkRCRpanIikjQ1ORFJWjwqnUXujubm5m4zb7/9NnUsZvvzmTNnhhlm8nznzp1UTcwkf0FBQZhhtqoGEJ5LALh48WKY2bNnD7VeTU1NmNmxY0eYaWpqCjPsVR/M9vWLFi0KM48++ii1HnMFSXFxcZhhr6I5ceJEmGHOeVlZWZhhriICgKKiojBTXl4eZlpaWqj1mCssuqNnciKSNDU5EUmampyIJE1NTkSSpiYnIklTkxORpKnJiUjS1OREJGl9Ogx84cKFcNB1xIgR1LH++te/hhlm0DcvLy/MsEOSDQ3xe3Bv3LgxzDzwwAPUesw5YIammYFhAHj++efDDDMoOnTo0DDzxhtvUDVl6x3gfvWrX1E5Zlvv+++/P8zU19dT61133XVhpqKiIszs2rUrzDCD1QA3yLxv374ww2xrDgDTp08PMxs2bOjyPj2TE5GkqcmJSNLU5EQkaWpyIpI0NTkRSZqanIgkTU1ORJKmJiciSTN377PF8vPzffTo0d1mLl26RB2rpKQkzDA7jzI7pra1tVE1MYOpra2tYSYnJ4dajxnKHDduXJhhdisGgLq6ujDD7IpbWloaZo4cOULVNGnSpDDDfH3M4DjADXwzjzvmXALAjBkzwgwz0H7o0KEwww5WM49hZsD8E5/4BLXe8ePHw8ymTZs2u3t1Z/fpmZyIJE1NTkSSpiYnIklTkxORpKnJiUjS1OREJGlqciKSNDU5EUmampyIJK1Pr3gwM4+mqh9++GHqWGvWrAkzY8aMCTPM189uC93U1BRmmO3I9+/fT63HHIuZdD99+jS1HjOh/uSTT4aZJ554IsxUV3c6vP4RzNUhzFUDq1atotaLrtgBuHPOXBkCcI8pZqtx5sqX+fPnUzX99re/DTPMlUSVlZXUeswVFqtXr+75FQ9mNtHM/mxmO81sh5k9lbm9zMzeNLM9mX/ja3VERPoY8+tqC4B/dfeZAG4D8A0zmwngaQBvufs0AG9lPhcRGVDCJufuR919S+bjRgC7AIwH8AiAJZnYEgCPXqUaRUR67IrektDMqgDMBbABwBh3P5q56xiATl8AM7NFABb1okYRkR6j/7pqZsMALAPwbXc/2/E+b3/1vtNX8N19sbtXd/WioIjI1UQ1OTPLQ3uD+7W7v5q5uc7MKjP3VwLg3i1XRKQPMX9dNQC/ALDL3Z/rcNcKAAszHy8EsDz75YmI9A7zmtwdAP4ZwDYzeydz23cAPAPgZTP7KoADAL5wVSoUEemFPh0GLioq8qqqqm4zH3zwAXWsCRMmhJm//e1vYYYZ7hwxYgRVE7OldW5u/P+VYcOGUesx258zA5fsttdFRUVhZs+ePWHmpptuCjPsgHJNTU2Y2bFjR5hhtz9nBrWZIXTmsQkAt9xyS5g5depUmGGGprdu3UrVNHv27DBTW1sbZtjtzw8fPhxmNmzYoO3PReTjSU1ORJKmJiciSVOTE5GkqcmJSNLU5EQkaWpyIpI0NTkRSdoV7ULSW3l5eeFuts3NzdSxWlpawkxFRUWYGTlyZJhhhmABIBp0Brhh2WnTplHrMYPcU6dODTPMzqsANwT6+OOPhxlm8HbZsmVUTczg9F133RVmDh48SK3HDGBPmjQpzJw5c4ZajxlELykpCTPMMPDYsWOpmpgccz4bGhqo9ZiB/e7omZyIJE1NTkSSpiYnIklTkxORpKnJiUjS1OREJGlqciKSNDU5EUmampyIJK1Pr3hobm4Otwhnt2OfPHlymGEm68vLy8PM9u3bqZqY7ZyZafG2tjZqvfr6+A3SiouLw0xjYyO13smTJ8MMM8U+Y8aMMFNaWkrVxJyrP/zhD2Fm7ty51HrsVQER5oodgHs7AGZL9rKysjBz9uzZMANwW7cPHz48zDBXGwHArl27qFxX9ExORJKmJiciSVOTE5GkqcmJSNLU5EQkaWpyIpI0NTkRSZqanIgkzdjh26wsZnYcwIEP3VwO4ESfFZE9g7VuYPDWPljrBgZv7YOl7mvcvdP3O+jTJtdpAWab3L26X4vogcFaNzB4ax+sdQODt/bBWndH+nVVRJKmJiciSRsITW5xfxfQQ4O1bmDw1j5Y6wYGb+2Dte6/6/fX5ERErqaB8ExOROSq6bcmZ2YPmNl7ZrbXzJ7urzp6wsz2m9k2M3vHzDb1dz1dMbMXzKzezLZ3uK3MzN40sz2Zf7mN2/pYF7V/38xqM+f9HTN7qD9r7IyZTTSzP5vZTjPbYWZPZW4f0Oe9m7oH/DmP9Muvq2aWA+B9APcCOAzgbQCPufvOPi+mB8xsP4Bqdx/Q80Nm9k8AzgH4X3eflbnt3wE0uPszmf+5lLr7v/VnnZ3povbvAzjn7v/Rn7V1x8wqAVS6+xYzGw5gM4BHAfwLBvB576buL2CAn/NIfz2Tmwdgr7vvc/dLAF4C8Eg/1ZIsd18F4MNb9T4CYEnm4yVofyAPOF3UPuC5+1F335L5uBHALgDjMcDPezd1D3r91eTGAzjU4fPDGFwn1AG8YWabzWxRfxdzhca4+9HMx8cAjOnPYnrgm2a2NfPr7ID6le/DzKwKwFwAGzCIzvuH6gYG0TnvjP7w0DPz3f0mAA8C+EbmV6tBx9tfqxhMf17/GYApAOYAOArg2X6tphtmNgzAMgDfdvd/ePOEgXzeO6l70JzzrvRXk6sFMLHD5xMytw0K7l6b+bcewO/Q/uv3YFGXef3l8usw8bvhDBDuXufure7eBuB5DNDzbmZ5aG8Uv3b3VzM3D/jz3lndg+Wcd6e/mtzbAKaZ2WQzywfwJQAr+qmWK2JmxZkXZmFmxQDuA8C9ndfAsALAwszHCwEs78darsjlJpHxWQzA825mBuAXAHa5+3Md7hrQ572rugfDOY/02zBw5k/RPwWQA+AFd/9RvxRyhczsWrQ/ewPa39LxNwO1djNbCuBOtO8kUQfgewBeA/AygElo3xHmC+4+4F7g76L2O9H+a5MD2A/g6x1e5xoQzGw+gP8DsA3A5fdL/A7aX98asOe9m7ofwwA/5xFd8SAiSdMfHkQkaWpyIpI0NTkRSZqanIgkTU1ORJKmJiciSVOTE5GkqcmJSNL+H7AoYOdoWqjXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.cla()\n",
    "ax.imshow(np.reshape(gen_alt3[0], (dim_height, dim_width)), cmap='gray')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.cla()\n",
    "ax.imshow(np.reshape(gen_alt4[0], (dim_height, dim_width)), cmap='gray')            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e973dce",
   "metadata": {},
   "source": [
    "# Resize to original shpe & Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d84d24d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABC</th>\n",
       "      <th>ACB</th>\n",
       "      <th>BAC</th>\n",
       "      <th>BCA</th>\n",
       "      <th>CAB</th>\n",
       "      <th>CBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047967</td>\n",
       "      <td>0.052468</td>\n",
       "      <td>0.102623</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.092883</td>\n",
       "      <td>0.068956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042824</td>\n",
       "      <td>0.045081</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>0.077102</td>\n",
       "      <td>0.060780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.041422</td>\n",
       "      <td>0.083894</td>\n",
       "      <td>0.062264</td>\n",
       "      <td>0.075189</td>\n",
       "      <td>0.053789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042977</td>\n",
       "      <td>0.043172</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>0.062150</td>\n",
       "      <td>0.080225</td>\n",
       "      <td>0.056160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047659</td>\n",
       "      <td>0.049378</td>\n",
       "      <td>0.092674</td>\n",
       "      <td>0.069921</td>\n",
       "      <td>0.082698</td>\n",
       "      <td>0.056301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABC       ACB       BAC       BCA       CAB       CBA\n",
       "0  0.047967  0.052468  0.102623  0.077700  0.092883  0.068956\n",
       "1  0.042824  0.045081  0.088500  0.062508  0.077102  0.060780\n",
       "2  0.039014  0.041422  0.083894  0.062264  0.075189  0.053789\n",
       "3  0.042977  0.043172  0.086369  0.062150  0.080225  0.056160\n",
       "4  0.047659  0.049378  0.092674  0.069921  0.082698  0.056301"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = np.math.factorial(6)\n",
    "img_width = 30\n",
    "img_height = 24\n",
    "ori_size = np.math.factorial(3)\n",
    "\n",
    "gen_alt3_ori = resize_to_ori(gen_alt3, img_size, img_width, img_height, ori_size, batch_size, iteration_generator)\n",
    "gen_alt3_pd = pd.DataFrame(gen_alt3_ori, columns = ['ABC', 'ACB', 'BAC', 'BCA', 'CAB', 'CBA'])\n",
    "print(gen_alt3_pd.shape)\n",
    "gen_alt3_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "266b6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_alt3_pd.to_csv(generated_path + 'generated_atl3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f74596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABCD</th>\n",
       "      <th>ACBD</th>\n",
       "      <th>BACD</th>\n",
       "      <th>BCAD</th>\n",
       "      <th>CABD</th>\n",
       "      <th>CBAD</th>\n",
       "      <th>DABC</th>\n",
       "      <th>DACB</th>\n",
       "      <th>DBAC</th>\n",
       "      <th>DBCA</th>\n",
       "      <th>...</th>\n",
       "      <th>BDAC</th>\n",
       "      <th>BDCA</th>\n",
       "      <th>CDAB</th>\n",
       "      <th>CDBA</th>\n",
       "      <th>ABDC</th>\n",
       "      <th>ACDB</th>\n",
       "      <th>BADC</th>\n",
       "      <th>BCDA</th>\n",
       "      <th>CADB</th>\n",
       "      <th>CBDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026425</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.061816</td>\n",
       "      <td>0.051633</td>\n",
       "      <td>0.053358</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.049070</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.084597</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078480</td>\n",
       "      <td>0.065638</td>\n",
       "      <td>0.130425</td>\n",
       "      <td>0.093457</td>\n",
       "      <td>0.062460</td>\n",
       "      <td>0.034821</td>\n",
       "      <td>0.054285</td>\n",
       "      <td>0.044731</td>\n",
       "      <td>0.076999</td>\n",
       "      <td>0.054766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.026503</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>0.047345</td>\n",
       "      <td>0.048826</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.041563</td>\n",
       "      <td>0.095374</td>\n",
       "      <td>0.080740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077475</td>\n",
       "      <td>0.065737</td>\n",
       "      <td>0.118736</td>\n",
       "      <td>0.093364</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>0.035742</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.045612</td>\n",
       "      <td>0.073628</td>\n",
       "      <td>0.062392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027547</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>0.066357</td>\n",
       "      <td>0.050623</td>\n",
       "      <td>0.051857</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.055795</td>\n",
       "      <td>0.041479</td>\n",
       "      <td>0.098971</td>\n",
       "      <td>0.084410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089807</td>\n",
       "      <td>0.068682</td>\n",
       "      <td>0.132911</td>\n",
       "      <td>0.097236</td>\n",
       "      <td>0.062626</td>\n",
       "      <td>0.036629</td>\n",
       "      <td>0.054150</td>\n",
       "      <td>0.048649</td>\n",
       "      <td>0.078823</td>\n",
       "      <td>0.060524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026020</td>\n",
       "      <td>0.024871</td>\n",
       "      <td>0.065171</td>\n",
       "      <td>0.054840</td>\n",
       "      <td>0.050372</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.043449</td>\n",
       "      <td>0.037521</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.074878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>0.065733</td>\n",
       "      <td>0.115150</td>\n",
       "      <td>0.091849</td>\n",
       "      <td>0.054119</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.042492</td>\n",
       "      <td>0.071094</td>\n",
       "      <td>0.051340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025484</td>\n",
       "      <td>0.027012</td>\n",
       "      <td>0.059440</td>\n",
       "      <td>0.047506</td>\n",
       "      <td>0.050620</td>\n",
       "      <td>0.042423</td>\n",
       "      <td>0.045088</td>\n",
       "      <td>0.035070</td>\n",
       "      <td>0.091792</td>\n",
       "      <td>0.079066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.117618</td>\n",
       "      <td>0.088294</td>\n",
       "      <td>0.056595</td>\n",
       "      <td>0.033740</td>\n",
       "      <td>0.051846</td>\n",
       "      <td>0.044567</td>\n",
       "      <td>0.074544</td>\n",
       "      <td>0.053946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ABCD      ACBD      BACD      BCAD      CABD      CBAD      DABC  \\\n",
       "0  0.026425  0.024765  0.061816  0.051633  0.053358  0.042280  0.049070   \n",
       "1  0.022834  0.026503  0.060569  0.047345  0.048826  0.037074  0.047225   \n",
       "2  0.027547  0.029678  0.066357  0.050623  0.051857  0.040148  0.055795   \n",
       "3  0.026020  0.024871  0.065171  0.054840  0.050372  0.044552  0.043449   \n",
       "4  0.025484  0.027012  0.059440  0.047506  0.050620  0.042423  0.045088   \n",
       "\n",
       "       DACB      DBAC      DBCA  ...      BDAC      BDCA      CDAB      CDBA  \\\n",
       "0  0.033234  0.084597  0.077996  ...  0.078480  0.065638  0.130425  0.093457   \n",
       "1  0.041563  0.095374  0.080740  ...  0.077475  0.065737  0.118736  0.093364   \n",
       "2  0.041479  0.098971  0.084410  ...  0.089807  0.068682  0.132911  0.097236   \n",
       "3  0.037521  0.091346  0.074878  ...  0.074761  0.065733  0.115150  0.091849   \n",
       "4  0.035070  0.091792  0.079066  ...  0.076449  0.063285  0.117618  0.088294   \n",
       "\n",
       "       ABDC      ACDB      BADC      BCDA      CADB      CBDA  \n",
       "0  0.062460  0.034821  0.054285  0.044731  0.076999  0.054766  \n",
       "1  0.058595  0.035742  0.055552  0.045612  0.073628  0.062392  \n",
       "2  0.062626  0.036629  0.054150  0.048649  0.078823  0.060524  \n",
       "3  0.054119  0.031248  0.049755  0.042492  0.071094  0.051340  \n",
       "4  0.056595  0.033740  0.051846  0.044567  0.074544  0.053946  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = np.math.factorial(6)\n",
    "img_width = 30\n",
    "img_height = 24\n",
    "ori_size = np.math.factorial(4)\n",
    "\n",
    "gen_alt4_ori = resize_to_ori(gen_alt4, img_size, img_width, img_height, ori_size, batch_size, iteration_generator)\n",
    "gen_alt4_pd = pd.DataFrame(gen_alt4_ori, columns = ['ABCD', 'ACBD', 'BACD', 'BCAD', 'CABD', 'CBAD', 'DABC',\n",
    "       'DACB', 'DBAC', 'DBCA', 'DCAB', 'DCBA', 'ADBC', 'ADCB', 'BDAC', 'BDCA',\n",
    "       'CDAB', 'CDBA', 'ABDC', 'ACDB', 'BADC', 'BCDA', 'CADB', 'CBDA'])\n",
    "print(gen_alt4_pd.shape)\n",
    "gen_alt4_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feab2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_alt4_pd.to_csv(generated_path + 'generated_atl4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a62a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.12",
   "language": "python",
   "name": "tf1.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
